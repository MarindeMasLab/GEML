{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0ba9e57-b4e8-4c10-82da-7633cea41469",
   "metadata": {},
   "source": [
    "# Data Analysis and Predictive Modeling with SHAP and XGBoost\n",
    "\n",
    "## Title  \n",
    "**Integrating Machine Learning with Metabolic Models for Precision Trauma Care: Personalized ENDOTYPE Stratification and Metabolic Target Identification**\n",
    "\n",
    "## Authors  \n",
    "- **Igor Marin de Mas** (Copenhagen University Hospital, Rigshospitalet)  \n",
    "- **Lincoln Moura** (Universidade Federal do Ceará)  \n",
    "- **Fernando Luiz Marcelo Antunes** (Universidade Federal do Ceará)  \n",
    "- **Josep Maria Guerrero** (Aalborg University)  \n",
    "- **Pär Ingemar Johansson** (Copenhagen University Hospital, Rigshospitalet)  \n",
    "\n",
    "## Description:\n",
    "This script aims to classify patient data using the XGBoost classifier while selecting the most important features based on SHAP values. The workflow includes:\n",
    "\n",
    "1. **Loading Preprocessed Data**: Reads patient data from CSV files.\n",
    "2. **Combining Data**: Merges individual patient datasets into a single DataFrame, ensuring data consistency.\n",
    "3. **Feature Selection**: Utilizes SHAP values to determine the most relevant features for classification.\n",
    "4. **Model Training and Evaluation**: Trains an XGBoost model on selected features and evaluates performance using confusion matrices and classification reports.\n",
    "5. **Feature Importance Visualization**: Plots the most influential features to enhance model interpretability.\n",
    "\n",
    "The script iterates through different feature subsets (top 50, 30, 20, 10) ranked by SHAP importance, training models and analyzing their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e3f143-fc18-4daa-adb7-8fdab2de0c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "# Third-party libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "import scikitplot as skplt\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2bbad1-ed5e-4972-92f6-0b6515ac1873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Utility Functions\n",
    "# -----------------------------\n",
    "\n",
    "def extract_patient_index(file_path):\n",
    "    \"\"\"\n",
    "    Extract the patient index from the file name using regex.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the file.\n",
    "\n",
    "    Returns:\n",
    "        int: Patient index extracted from the file name.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the index cannot be extracted from the file name.\n",
    "    \"\"\"\n",
    "    match = re.search(r'(\\d+)', os.path.basename(file_path))\n",
    "    if match:\n",
    "        return int(match.group(1)) - 1\n",
    "    else:\n",
    "        raise ValueError(f\"Cannot extract index from file name: {file_path}\")\n",
    "\n",
    "def load_preprocessed_data(preprocessed_path, num_patients):\n",
    "    \"\"\"\n",
    "    Load preprocessed patient data from CSV files.\n",
    "\n",
    "    Args:\n",
    "        preprocessed_path (str): Path to the directory with preprocessed data.\n",
    "        num_patients (int): Number of patients.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of patient DataFrames indexed by patient number.\n",
    "        list: List of indices for successfully loaded patients.\n",
    "    \"\"\"\n",
    "    patients = {x: None for x in range(num_patients)}\n",
    "    test_indices = []\n",
    "\n",
    "    for file_path in glob.glob(os.path.join(preprocessed_path, '*.csv')):\n",
    "        try:\n",
    "            index = extract_patient_index(file_path)\n",
    "            test_indices.append(index)\n",
    "            patients[index] = pd.read_csv(file_path, index_col=0)\n",
    "        except ValueError as e:\n",
    "            print(f\"[ERROR] {e}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Could not load file: {file_path}. Error: {e}\")\n",
    "            continue\n",
    "\n",
    "    return patients, test_indices\n",
    "\n",
    "def combine_patient_data(patients, test_indices, target):\n",
    "    \"\"\"\n",
    "    Combine individual patient data into a single DataFrame with target labels.\n",
    "\n",
    "    Args:\n",
    "        patients (dict): Dictionary of patient DataFrames.\n",
    "        test_indices (list): List of indices for patients.\n",
    "        target (list): Target labels for patients.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame with all patient data and target labels.\n",
    "    \"\"\"\n",
    "    dataframes = []\n",
    "\n",
    "    for i in test_indices:\n",
    "        temp = patients[i].T\n",
    "        temp[\"target\"] = target[i]\n",
    "        dataframes.append(temp)\n",
    "\n",
    "    df = pd.concat(dataframes, axis=0).reset_index(drop=True)\n",
    "\n",
    "    if df.isna().sum().sum() > 0:\n",
    "        print(\"[WARNING] Missing values detected. Filling with column means.\")\n",
    "        df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def conf_matrix(clf, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Plot confusion matrices for training and testing predictions.\n",
    "\n",
    "    Args:\n",
    "        clf: Trained classifier.\n",
    "        X_train: Training data.\n",
    "        X_test: Testing data.\n",
    "        y_train: Training labels.\n",
    "        y_test: Testing labels.\n",
    "    \"\"\"\n",
    "    Y_train_pred = clf.predict(X_train)\n",
    "    Y_test_pred = clf.predict(X_test)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    skplt.metrics.plot_confusion_matrix(Y_train_pred, y_train, normalize=False, title=\"Training Confusion Matrix\", cmap=\"Oranges\", ax=axes[0])\n",
    "    skplt.metrics.plot_confusion_matrix(Y_test_pred, y_test, normalize=False, title=\"Testing Confusion Matrix\", cmap=\"Purples\", ax=axes[1])\n",
    "    plt.show()\n",
    "\n",
    "def train_and_evaluate(feature_set, num_iterations=10):\n",
    "    \"\"\"\n",
    "    Train and evaluate an XGBoost model on a given feature set.\n",
    "\n",
    "    Args:\n",
    "        feature_set (list): List of feature names to be used in training.\n",
    "        num_iterations (int): Number of times to repeat training.\n",
    "    \"\"\"\n",
    "    for i in range(num_iterations):\n",
    "        X, y = df.loc[:, feature_set], df['target'] - 1\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "        \n",
    "        model = XGBClassifier(objective='multi:softmax')\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        conf_matrix(model, X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        plt.figure(figsize=(20, 6))\n",
    "        importance_df = pd.DataFrame(model.feature_importances_, index=feature_set, columns=[f\"Importance_{i}\"])\n",
    "        importance_df.sort_values(by=f\"Importance_{i}\", ascending=False).head(50).plot.bar(figsize=(20, 3))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39e268d-ca4f-4597-9f57-a2e1201212ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Load Data\n",
    "# -----------------------------\n",
    "\n",
    "# Load target labels\n",
    "print(\"Loading target data...\")\n",
    "target_df = pd.read_csv(\"Patient_Trauma_Groups.csv\", delimiter=\";\")\n",
    "target = target_df[\"Metabo-group\"].values\n",
    "\n",
    "# Load patient data\n",
    "print(\"Loading patient data...\")\n",
    "preprocessed_path = \"preprocess_PCA/\"\n",
    "num_patients = 95\n",
    "patients, test_indices = load_preprocessed_data(preprocessed_path, num_patients)\n",
    "\n",
    "# Combine patient data into a single DataFrame\n",
    "df = combine_patient_data(patients, test_indices, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73343313-ad1d-4733-93a8-1809a7cff864",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load feature rankings\n",
    "df_global = pd.read_csv(\"Ranking_global_sharp.csv\", index_col=0)\n",
    "feature_sets = {\n",
    "    \"top50\": df_global.sort_values(by='Soma', ascending=False).head(50).index,\n",
    "    \"top30\": df_global.sort_values(by='Soma', ascending=False).head(30).index,\n",
    "    \"top20\": df_global.sort_values(by='Soma', ascending=False).head(20).index,\n",
    "    \"top10\": df_global.sort_values(by='Soma', ascending=False).head(10).index\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Model Training and Evaluation\n",
    "# -----------------------------\n",
    "\n",
    "# Train models on different feature sets\n",
    "for feature_name, features in feature_sets.items():\n",
    "    print(f\"\\nTraining model with {feature_name} features...\")\n",
    "    train_and_evaluate(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f06868f-c330-45d0-92bd-b89708501947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
